{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1ï¸âƒ£ Understanding the Perceptron\n",
    "\n",
    "A perceptron follows these steps:\n",
    "\n",
    "1. **Initialize weights** (including a bias).\n",
    "2. **Compute weighted sum** of inputs.\n",
    "3. **Apply activation function** (Step Function).\n",
    "4. **Update weights** using the learning rule.\n",
    "\n",
    "> **Weight Update Rule**  \n",
    "> $$\n",
    "> w_j = w_j + \\eta (y_{\\text{true}} - y_{\\text{pred}}) x_j\n",
    "> $$\n",
    "> where:\n",
    "$$ \\eta $$ \n",
    "= learning rate  \n",
    "$$ y_{\\text{true}} $$ \n",
    "= actual label  \n",
    "$$ y_{\\text{pred}} $$\n",
    "= perceptron output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2ï¸âƒ£ Implementing a Perceptron in Python**\n",
    "Let's implement a **Perceptron class** that can be trained on logic gates like AND, OR, but fails on XOR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, input_size, learning_rate=0.1, epochs=1000):\n",
    "        self.weights = np.random.randn(input_size + 1)  # +1 for bias\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def activation(self, x):\n",
    "        return 1 if x >= 0 else 0\n",
    "\n",
    "    def train(self, X, y):\n",
    "        X = np.insert(X, 0, 1, axis=1)  # Add bias term\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            total_error = 0\n",
    "            for i in range(len(X)):\n",
    "                weighted_sum = np.dot(X[i], self.weights)\n",
    "                y_pred = self.activation(weighted_sum)\n",
    "                error = y[i] - y_pred\n",
    "\n",
    "                # Update weights\n",
    "                self.weights += self.learning_rate * error * X[i]\n",
    "                total_error += abs(error)\n",
    "            \n",
    "            if total_error == 0:  # Stop if fully trained\n",
    "                break\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.insert(X, 0, 1, axis=1)\n",
    "        return np.array([self.activation(np.dot(x, self.weights)) for x in X])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3ï¸âƒ£ Training the Perceptron on AND Gate**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [0 0] -> Prediction: 0\n",
      "Input: [0 1] -> Prediction: 1\n",
      "Input: [1 0] -> Prediction: 0\n",
      "Input: [1 1] -> Prediction: 1\n"
     ]
    }
   ],
   "source": [
    "# AND Dataset\n",
    "X_and = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_and = np.array([0, 0, 0, 1])  # AND gate output\n",
    "\n",
    "# Initialize and train\n",
    "perceptron_and = Perceptron(input_size=2, learning_rate=0.1, epochs=10)\n",
    "perceptron_and.train(X_and, y_and)\n",
    "\n",
    "# Test Predictions\n",
    "predictions_and = perceptron_and.predict(X_and)\n",
    "\n",
    "for i in range(len(X_and)):\n",
    "    print(f\"Input: {X_and[i]} -> Prediction: {predictions_and[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœ” Perceptron successfully classifies AND gate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train Perceptron on XOR**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [0 0] -> Prediction: 1\n",
      "Input: [0 1] -> Prediction: 0\n",
      "Input: [1 0] -> Prediction: 0\n",
      "Input: [1 1] -> Prediction: 0\n"
     ]
    }
   ],
   "source": [
    "# XOR Dataset\n",
    "X_xor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y_xor = np.array([0, 1, 1, 0])  # XOR gate output\n",
    "\n",
    "# Train Perceptron\n",
    "perceptron_xor = Perceptron(input_size=2, learning_rate=0.1, epochs=1000)\n",
    "perceptron_xor.train(X_xor, y_xor)\n",
    "\n",
    "# Test Predictions\n",
    "predictions_xor = perceptron_xor.predict(X_xor)\n",
    "\n",
    "for i in range(len(X_xor)):\n",
    "    print(f\"Input: {X_xor[i]} -> Prediction: {predictions_xor[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ’¡ The perceptron fails to classify (0,1) and (1,0) correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Key Takeaways**\n",
    "âœ” **Simple but powerful learning algorithm.**  \n",
    "âœ” **Works only for linearly separable problems.**    \n",
    "âœ” **XOR requires a non-linear decision boundary.**  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
